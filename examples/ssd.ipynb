{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD\n",
    "\n",
    "This is to go through each important step of SSD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, load the model. You only need to do this one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('..')\n",
    "caffe_root = './'\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import time\n",
    "\n",
    "import caffe\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "# caffe.set_mode_cpu()\n",
    "# We create a solver that fine-tunes from a previously trained network.\n",
    "solver = caffe.SGDSolver(caffe_root + 'models/VGGNet/VOC0712/SSD_300x300_score/solver.prototxt')\n",
    "# solver.net.copy_from(caffe_root + 'models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel')\n",
    "solver.net.copy_from(caffe_root + 'models/VGGNet/VOC0712/SSD_300x300/VGG_VOC0712_SSD_300x300_iter_60000.caffemodel')\n",
    "\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "transformer = caffe.io.Transformer({'data': solver.net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2, 0, 1))\n",
    "transformer.set_mean('data', np.array([104,117,123])) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "net = solver.net\n",
    "print 'xx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "# load PASCAL VOC labels\n",
    "labelmap_file = 'data/VOC0712/labelmap_voc.prototxt'\n",
    "file = open(labelmap_file, 'r')\n",
    "labelmap = caffe_pb2.LabelMap()\n",
    "text_format.Merge(str(file.read()), labelmap)\n",
    "\n",
    "def get_labelname(labelmap, labels):\n",
    "    num_labels = len(labelmap.item)\n",
    "    labelnames = []\n",
    "    if type(labels) is not list:\n",
    "        labels = [labels]\n",
    "    for label in labels:\n",
    "        found = False\n",
    "        for i in xrange(0, num_labels):\n",
    "            if label == labelmap.item[i].label:\n",
    "                found = True\n",
    "                labelnames.append(labelmap.item[i].display_name)\n",
    "                break\n",
    "        assert found == True\n",
    "    return labelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward one step.\n",
    "solver.step(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the annotated datum after one forward-backward step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "\n",
    "img_blob = net.blobs['data'].data\n",
    "num_imgs = img_blob.shape[0]\n",
    "img_width = img_blob.shape[2]\n",
    "img_height = img_blob.shape[3]\n",
    "label_blob = net.blobs['label'].data[0,0,:,:]\n",
    "num_labels = label_blob.shape[0]\n",
    "\n",
    "for i in xrange(num_imgs):\n",
    "    img = transformer.deprocess('data', img_blob[i])\n",
    "    plt.subplot(1, num_imgs, i + 1)\n",
    "    plt.imshow(img)\n",
    "    currentAxis = plt.gca()\n",
    "    for j in xrange(num_labels):\n",
    "        gt_bbox = label_blob[j, :]\n",
    "        if gt_bbox[0] == i:\n",
    "            xmin = gt_bbox[3] * img_width\n",
    "            ymin = gt_bbox[4] * img_height\n",
    "            xmax = gt_bbox[5] * img_width\n",
    "            ymax = gt_bbox[6] * img_height\n",
    "            gt_label = int(gt_bbox[1])\n",
    "            coords = (xmin, ymin), xmax - xmin + 1, ymax - ymin + 1\n",
    "            color = colors[gt_label]\n",
    "            currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n",
    "            label = get_labelname(labelmap, gt_bbox[1])[0]\n",
    "            currentAxis.text(xmin, ymin, label, bbox={'facecolor':color, 'alpha':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take an array of shape (n, height, width) or (n, height, width, channels)\n",
    "# and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)\n",
    "def vis_square(data, padsize=1, padval=0):\n",
    "    data -= data.min()\n",
    "    data /= data.max()\n",
    "    \n",
    "    # force the number of filters to be square\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n",
    "    \n",
    "    # tile the filters into an image\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    \n",
    "    plt.imshow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the conv1_1's filters to make sure we have loaded a good pretrained model. Otherwise, it should plot random noise squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the parameters are a list of [weights, biases]\n",
    "filters = net.params['conv1_1'][0].data\n",
    "vis_square(filters.transpose(0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's visualize conv5_3 layer responses. You should see nicely pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat = net.blobs['conv5_3'].data[0, :]\n",
    "vis_square(feat, padval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the PermuteLayer is doing the right thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc7_mbox_loc = net.blobs['fc7_mbox_loc'].data\n",
    "print fc7_mbox_loc[0,:,1,2]\n",
    "\n",
    "fc7_mbox_loc_perm = net.blobs['fc7_mbox_loc_perm'].data\n",
    "print fc7_mbox_loc_perm[0,1,2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the PriorBoxLayer generates the correct priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_blob = net.blobs['data'].data\n",
    "num_imgs = img_blob.shape[0]\n",
    "img_width = img_blob.shape[2]\n",
    "img_height = img_blob.shape[3]\n",
    "\n",
    "priorbox = net.blobs['mbox_priorbox'].data[0,0,:]\n",
    "num_priors = priorbox.shape[0]\n",
    "\n",
    "colors='rgbcmy'\n",
    "for i in xrange(num_imgs):\n",
    "    img = transformer.deprocess('data', img_blob[i])\n",
    "    plt.subplot(1, num_imgs, i + 1)\n",
    "    plt.imshow(img)\n",
    "    currentAxis = plt.gca()\n",
    "    for j in xrange(240,243):\n",
    "        prior_bbox = priorbox[j*4:(j+1)*4]\n",
    "        xmin = prior_bbox[0] * img_width\n",
    "        ymin = prior_bbox[1] * img_height\n",
    "        xmax = prior_bbox[2] * img_width\n",
    "        ymax = prior_bbox[3] * img_height\n",
    "        coords = (xmin, ymin), xmax - xmin + 1, ymax - ymin + 1\n",
    "        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=colors[j%4], linewidth=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
